# D·ª± √Ån Ph√¢n Lo·∫°i C·∫£m X√∫c B√¨nh Lu·∫≠n Ti·∫øng Vi·ªát

## I. Gi·ªõi Thi·ªáu T·ªïng Quan

ƒê√¢y l√† m·ªôt d·ª± √°n nghi√™n c·ª©u v·ªÅ ph√¢n lo·∫°i c·∫£m x√∫c b√¨nh lu·∫≠n ti·∫øng Vi·ªát, s·ª≠ d·ª•ng c√°c ph∆∞∆°ng ph√°p Machine Learning truy·ªÅn th·ªëng k·∫øt h·ª£p v·ªõi k·ªπ thu·∫≠t gi·∫£m chi·ªÅu d·ªØ li·ªáu. D·ª± √°n t·∫≠p trung v√†o vi·ªác x√¢y d·ª±ng v√† so s√°nh hi·ªáu su·∫•t c·ªßa nhi·ªÅu m√¥ h√¨nh kh√°c nhau tr√™n b√†i to√°n ph√¢n lo·∫°i ƒëa l·ªõp v·ªõi 7 nh√£n c·∫£m x√∫c.

**M·ª•c ti√™u ch√≠nh:**
- X√¢y d·ª±ng b·ªô d·ªØ li·ªáu c·∫£m x√∫c ti·∫øng Vi·ªát t·ª´ 2 ngu·ªìn ch√≠nh: UIT-VSMEC v√† Facebook
- √Åp d·ª•ng pipeline ti·ªÅn x·ª≠ l√Ω b√¨nh lu·∫≠n ti·∫øng Vi·ªát
- Th·ª≠ nghi·ªám v√† ƒë√°nh gi√° 2 m√¥ h√¨nh Machine Learning v·ªõi 2 k·ªπ thu·∫≠t gi·∫£m chi·ªÅu kh√°c nhau (PCA, LDA)
- So s√°nh hi·ªáu qu·∫£ c·ªßa c√°c ph∆∞∆°ng ph√°p tr√™n c√°c t·ª∑ l·ªá chia d·ªØ li·ªáu kh√°c nhau

**C√°c m√¥ h√¨nh ƒë∆∞·ª£c s·ª≠ d·ª•ng:**
- Logistic Regression (Multinomial Softmax)
- K-Nearest Neighbors (K-NN) v·ªõi Cosine Similarity

**K·ªπ thu·∫≠t gi·∫£m chi·ªÅu:**
- PCA (Principal Component Analysis) - gi·∫£m chi·ªÅu kh√¥ng gi√°m s√°t
- LDA (Linear Discriminant Analysis) - gi·∫£m chi·ªÅu c√≥ gi√°m s√°t

---

## II. Ngu·ªìn D·ªØ Li·ªáu

### 1. UIT-VSMEC Dataset

**M√¥ t·∫£:** 
UIT-VSMEC (Vietnamese Social Media Emotion Corpus) l√† b·ªô d·ªØ li·ªáu chu·∫©n v·ªÅ ph√¢n lo·∫°i c·∫£m x√∫c ti·∫øng Vi·ªát ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Tr∆∞·ªùng ƒê·∫°i h·ªçc B√°ch khoa - ƒêHQG TP.HCM. B·ªô d·ªØ li·ªáu n√†y t·∫≠p trung v√†o c√°c b√¨nh lu·∫≠n tr√™n m·∫°ng x√£ h·ªôi v·ªõi ng√¥n ng·ªØ t·ª± nhi√™n, phi ch√≠nh th·ª©c (t·ª´ l√≥ng, t·ª´ vi·∫øt t·∫Øt).

**Ngu·ªìn:** Hugging Face Datasets (`ura-hcmut/UIT-VSMEC`)

**Th√¥ng tin chi ti·∫øt:**
- T·∫≠p hu·∫•n luy·ªán (Train): 5548 m·∫´u
- T·∫≠p ki·ªÉm ƒë·ªãnh (Validation): 686 m·∫´u
- T·∫≠p ki·ªÉm tra (Test): 693 m·∫´u
- T·ªïng c·ªông: **6927 m·∫´u**

### 2. B·ªô D·ªØ Li·ªáu T·ª± Thu Th·∫≠p v√† G√°n Nh√£n (HUSFBcGp)

**M√¥ t·∫£:**
Ngo√†i UIT-VSMEC, d·ª± √°n c√≤n b·ªï sung b·ªô d·ªØ li·ªáu ƒë∆∞·ª£c t·ª± thu th·∫≠p t·ª´ m·∫°ng x√£ h·ªôi Facebook v√† ƒë∆∞·ª£c g√°n nh√£n th·ªß c√¥ng b·ªüi nh√≥m. Vi·ªác thu th·∫≠p v√† g√°n nh√£n tu√¢n theo c√πng ti√™u chu·∫©n v·ªõi UIT-VSMEC ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n.

**Quy tr√¨nh t√≥m t·∫Øt:**
- Thu th·∫≠p b√¨nh lu·∫≠n ti·∫øng Vi·ªát t·ª´ m·∫°ng x√£ h·ªôi Facebook
- L√†m s·∫°ch v√† l·ªçc c√°c m·∫´u kh√¥ng h·ª£p l·ªá
- G√°n nh√£n th·ªß c√¥ng b·ªüi nhi·ªÅu ng∆∞·ªùi ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c
- Ki·ªÉm tra ch√©o v√† ƒë·ªìng thu·∫≠n v·ªÅ nh√£n cu·ªëi c√πng

**Th√¥ng tin chi ti·∫øt:**
- S·ªë l∆∞·ª£ng m·∫´u: **4616 m·∫´u**
- File d·ªØ li·ªáu: `data/raw_data_final.csv`

### 3. B·ªô D·ªØ Li·ªáu T·ªïng H·ª£p (UIT-VSMEC-HUSFBcGp)

**Sau khi g·ªôp hai ngu·ªìn d·ªØ li·ªáu:**
- T·ªïng s·ªë m·∫´u *(ch∆∞a ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu)*: **11543 m·∫´u**
- Sau khi ti·ªÅn x·ª≠ l√Ω, EDA v√† lo·∫°i b·ªè ngo·∫°i lai: **10780 m·∫´u**
- S·ªë nh√£n c·∫£m x√∫c: **7 nh√£n**
- Ph√¢n b·ªë d·ªØ li·ªáu: Kh√¥ng c√¢n b·∫±ng (imbalanced), nh√£n "Enjoyment" chi·∫øm ƒëa s·ªë

**C√°c nh√£n c·∫£m x√∫c:**
1. **Enjoyment** - Th√≠ch th√∫, vui v·∫ª
2. **Sadness** - Bu·ªìn b√£
3. **Anger** - T·ª©c gi·∫≠n
4. **Fear** - S·ª£ h√£i
5. **Surprise** - Ng·∫°c nhi√™n
6. **Disgust** - Gh√™ t·ªüm
7. **Other** - C·∫£m x√∫c kh√°c

**Chia t·∫≠p d·ªØ li·ªáu:**
- Train + Validation: 8624 m·∫´u (80%)
- Test: 2156 m·∫´u (20%)
- C√°c t·ª∑ l·ªá Train:Validation ƒë∆∞·ª£c th·ª≠ nghi·ªám: 8:2, 7:3, 6:4

---

## III. Quy Tr√¨nh Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu

D·ª± √°n √°p d·ª•ng m·ªôt pipeline ti·ªÅn x·ª≠ l√Ω 13 b∆∞·ªõc cho b√¨nh lu·∫≠n ti·∫øng Vi·ªát:

### 1. L√†m S·∫°ch C∆° B·∫£n (B∆∞·ªõc 1-5)

1. **Lo·∫°i b·ªè null kh·ªèi d·ªØ li·ªáu**
   - X√≥a c√°c d√≤ng d·ªØ li·ªáu kh√¥ng c√≥ n·ªôi dung

2. **Chu·∫©n h√≥a ch·ªØ th∆∞·ªùng**
   - Chuy·ªÉn to√†n b·ªô b√¨nh lu·∫≠n v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ ƒë·ªìng nh·∫•t

3. **Chuy·ªÉn k√Ω t·ª± l·∫∑p l·∫°i li√™n ti·∫øp th√†nh 1 k√Ω t·ª± ƒë∆°n**
   - "ƒë·∫πpppp" => "ƒë·∫πp"
   - "yayyyy" => "yay"

4. **Thay th·∫ø c√°c Emoji v√† Emoticon th√†nh t·ª´ ti·∫øng Vi·ªát**
   - `:)` => `<c∆∞·ªùi>`
   - `üòÇ` => `<c∆∞·ªùi_ch·∫£y_n∆∞·ªõc_m·∫Øt>`
   - `‚ù§Ô∏è` => `<tim>`
   - `T_T` => `<kh√≥c>`

5. **Chu·∫©n h√≥a t·ª´ vi·∫øt t·∫Øt v√† ti·∫øng l√≥ng**
   - "ko" => "kh√¥ng"
   - "k" => "kh√¥ng"
   - "oke" => "ok"

### 2. B∆∞·ªõc 6-9

6. **X√≥a c√°c d√≤ng c√≥ d·∫•u thanh b·ªã t√°ch r·ªùi**
   - Lo·∫°i b·ªè c√°c b√¨nh lu·∫≠n b·ªã l·ªói Unicode (d·∫•u thanh t√°ch r·ªùi kh·ªèi ch·ªØ c√°i)

7. **X√≥a k√Ω t·ª± ƒë·∫∑c bi·ªát**
   - Gi·ªØ l·∫°i c√°c k√Ω t·ª± ch·ªØ c√°i, s·ªë, v√† m·ªôt s·ªë d·∫•u c√¢u c·∫ßn thi·∫øt (`_`, `.`, `;`, `,`, `!`, `?`)

8. **Chu·∫©n h√≥a ch√≠nh t·∫£ v·ªõi Underthesea**
   - S·ª≠ d·ª•ng th∆∞ vi·ªán `underthesea` ƒë·ªÉ chu·∫©n h√≥a ch√≠nh t·∫£ ti·∫øng Vi·ªát

9. **Lo·∫°i b·ªè tr√πng l·∫∑p, x√©t tr√™n c·ªôt Sentence**
   - X√≥a c√°c m·∫´u c√≥ n·ªôi dung gi·ªëng h·ªát nhau

### 3. Tokenization v√† Ho√†n Thi·ªán (B∆∞·ªõc 10-13)

10. **T√°ch t·ª´ (Word Tokenization)**
    - S·ª≠ d·ª•ng `underthesea` ƒë·ªÉ t√°ch t·ª´ ti·∫øng Vi·ªát
    - "H√¥m nay tr·ªùi ƒë·∫πp qu√°" => ["H√¥m_nay", "tr·ªùi", "ƒë·∫πp", "qu√°"]

11. **Lo·∫°i b·ªè d·∫•u c√¢u sau tokenization**
    - Lo·∫°i b·ªè c√°c d·∫•u c√¢u kh√¥ng c·∫ßn thi·∫øt sau khi ƒë√£ t√°ch t·ª´

12. **Lo·∫°i b·ªè t·ª´ d·ª´ng (Stopwords)**
    - Lo·∫°i b·ªè c√°c t·ª´ ph·ªï bi·∫øn kh√¥ng mang nhi·ªÅu √Ω nghƒ©a: "v√†", "l√†", "c√≥", "c·ªßa", "cho", "v·ªõi", v.v.

13. **Lo·∫°i b·ªè d√≤ng r·ªóng**
    - Lo·∫°i b·ªè c√°c d√≤ng tr·ªü th√†nh r·ªóng sau qu√° tr√¨nh x·ª≠ l√Ω

**Th∆∞ vi·ªán s·ª≠ d·ª•ng:**
- `underthesea` - X·ª≠ l√Ω ng√¥n ng·ªØ ti·∫øng Vi·ªát
- `pandas` - X·ª≠ l√Ω d·ªØ li·ªáu d·∫°ng b·∫£ng
- `re` (regex) - X·ª≠ l√Ω chu·ªói v·ªõi bi·ªÉu th·ª©c ch√≠nh quy

---

## IV. C·∫•u Tr√∫c Th∆∞ M·ª•c

```
0_final/
‚îÇ
‚îú‚îÄ‚îÄ README.md                          # T√†i li·ªáu h∆∞·ªõng d·∫´n d·ª± √°n
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ raw_data_final.csv             # D·ªØ li·ªáu th√¥ sau khi g·ªôp 2 b·ªô d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ final_checked_data.csv         # D·ªØ li·ªáu t·ª± g√°n nh√£n (HUSFBcGp)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ cleaned_final/                 # D·ªØ li·ªáu sau ti·ªÅn x·ª≠ l√Ω
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processed_comments.csv     # To√†n b·ªô d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω (ch∆∞a lo·∫°i b·ªè ngo·∫°i lai)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_valid_processed_comments.csv  # T·∫≠p train+valid (80%)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_processed_comments.csv         # T·∫≠p test (20%)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ UIT_VSMEC/                     # Dataset g·ªëc t·ª´ UIT
‚îÇ       ‚îú‚îÄ‚îÄ vsmec_merged.csv           # G·ªôp train+valid+test
‚îÇ       ‚îú‚îÄ‚îÄ vsmec_train.csv            # T·∫≠p train g·ªëc
‚îÇ       ‚îú‚îÄ‚îÄ vsmec_valid.csv            # T·∫≠p validation g·ªëc
‚îÇ       ‚îî‚îÄ‚îÄ vsmec_test.csv             # T·∫≠p test g·ªëc
‚îÇ
‚îú‚îÄ‚îÄ data_build.ipynb                   # Notebook 1: X√¢y d·ª±ng b·ªô d·ªØ li·ªáu
‚îú‚îÄ‚îÄ preprocessing.ipynb    # Notebook 2: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
‚îú‚îÄ‚îÄ eda.ipynb                          # Notebook 3: Ph√¢n t√≠ch kh√°m ph√° d·ªØ li·ªáu
‚îú‚îÄ‚îÄ pca_lda.ipynb                      # Notebook 4: Th·ª≠ nghi·ªám gi·∫£m chi·ªÅu
‚îî‚îÄ‚îÄ modeling.ipynb               # Notebook 5: Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh
```

---

## V. Pipeline Th·ª±c Nghi·ªám

### 1. T·ªïng Quan Pipeline

D·ª± √°n th·ª±c hi·ªán m·ªôt pipeline ho√†n ch·ªânh t·ª´ x√¢y d·ª±ng d·ªØ li·ªáu ƒë·∫øn ƒë√°nh gi√° m√¥ h√¨nh:

```
[X√¢y d·ª±ng d·ªØ li·ªáu] => [Ti·ªÅn x·ª≠ l√Ω] => [EDA] => [TF-IDF, PCA, LDA] => [Modeling] => [Evaluation]
```

### 2. Chi Ti·∫øt C√°c B∆∞·ªõc

#### B∆∞·ªõc 1: X√¢y D·ª±ng B·ªô D·ªØ Li·ªáu (`data_build.ipynb`)

**M·ª•c ti√™u:** X√¢y d·ª±ng b·ªô d·ªØ li·ªáu c·∫£m x√∫c ti·∫øng Vi·ªát t·ª´ 2 ngu·ªìn ch√≠nh: UIT-VSMEC v√† Facebook

**Quy tr√¨nh:**
1. T·∫£i UIT-VSMEC dataset t·ª´ Hugging Face
2. ƒê·ªçc b·ªô d·ªØ li·ªáu t·ª± g√°n nh√£n (`final_checked_data.csv`)
3. G·ªôp hai ngu·ªìn d·ªØ li·ªáu th√†nh m·ªôt
4. L∆∞u k·∫øt qu·∫£ v√†o `raw_data_final.csv`

**Output:**
- `data/raw_data_final.csv` - D·ªØ li·ªáu th√¥ t·ªïng h·ª£p
- `data/UIT_VSMEC/*.csv` - C√°c file dataset g·ªëc

#### B∆∞·ªõc 2: Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu (`preprocessing_final_final.ipynb`)

**M·ª•c ti√™u:** L√†m s·∫°ch v√† chu·∫©n h√≥a b√¨nh lu·∫≠n ti·∫øng Vi·ªát

**Quy tr√¨nh:** √Åp d·ª•ng 13 b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω *(xem ph·∫ßn "Quy Tr√¨nh Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu")*

**Output:**
- `data/cleaned_final/processed_comments.csv` - D·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω ho√†n ch·ªânh

#### B∆∞·ªõc 3: Ph√¢n T√≠ch Kh√°m Ph√° D·ªØ Li·ªáu (`eda.ipynb`)

**M·ª•c ti√™u:** Hi·ªÉu s√¢u v·ªÅ ƒë·∫∑c ƒëi·ªÉm v√† ph√¢n b·ªë d·ªØ li·ªáu

**C√°c ph√¢n t√≠ch th·ª±c hi·ªán:**

1. **T·ªïng quan**
   - S·ªë l∆∞·ª£ng m·∫´u sau khi ti·ªÅn x·ª≠ l√Ω: **11,380**
   - S·ªë nh√£n: 7
   - Ph√¢n b·ªë nh√£n: Kh√¥ng c√¢n b·∫±ng (Enjoyment chi·∫øm ƒëa s·ªë)

2. **Ph√¢n t√≠ch ƒë·ªô d√†i c√¢u**
   - T√≠nh ƒë·ªô d√†i token cho m·ªói c√¢u
   - Ph√°t hi·ªán outliers b·∫±ng ph∆∞∆°ng ph√°p IQR
   - Lo·∫°i b·ªè 41 m·∫´u c√≥ ƒë·ªô d√†i > 500 tokens
   - Ng∆∞·ª°ng d∆∞·ªõi: -46.875, ng∆∞·ª°ng tr√™n: 174.125

```
S·ªë l∆∞·ª£ng d√≤ng lo·∫°i b·ªè sau khi lo·∫°i b·ªè outliner: 600
K√≠ch th∆∞·ªõc b·ªô d·ªØ li·ªáu sau khi lo·∫°i b·ªè outliner: (10780, 4)
```   

3. **Ph√¢n t√≠ch t·ª´ v√† c·ªôt Emotion (nh√£n) sau khi lo·∫°i b·ªè outliers**
   - V·∫Ω WordCloud cho t·ª´ng nh√£n c·∫£m x√∫c
   - Th·ªëng k√™ s·ªë l∆∞·ª£ng nh√£n

4. **Chia t·∫≠p d·ªØ li·ªáu**
   - Train+Valid : Test = 8:2 (stratified split)
   - ƒê·∫£m b·∫£o ph√¢n b·ªë nh√£n t∆∞∆°ng ƒë∆∞∆°ng gi·ªØa c√°c t·∫≠p

**Output:**
- `data/cleaned_final/train_valid_processed_comments.csv` - 8624 m·∫´u
- `data/cleaned_final/test_processed_comments.csv` - 2156 m·∫´u
- C√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch tr·ª±c quan

#### B∆∞·ªõc 4: Th·ª≠ Nghi·ªám Gi·∫£m Chi·ªÅu (`pca_lda.ipynb`)

**M·ª•c ti√™u:** Kh√°m ph√° hi·ªáu qu·∫£ c·ªßa c√°c k·ªπ thu·∫≠t gi·∫£m chi·ªÅu

**K·ªπ thu·∫≠t ƒë∆∞·ª£c th·ª≠ nghi·ªám:**

1. **PCA (Principal Component Analysis)**
   - Ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu kh√¥ng gi√°m s√°t
   - Gi·ªØ l·∫°i 90% ph∆∞∆°ng sai c·ªßa d·ªØ li·ªáu

2. **LDA (Linear Discriminant Analysis)**
   - Ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu c√≥ gi√°m s√°t
   - T·ªëi ƒëa h√≥a kho·∫£ng c√°ch gi·ªØa c√°c l·ªõp
   - K·∫øt qu·∫£: Gi·∫£m xu·ªëng 6 chi·ªÅu (n_classes - 1 = 7 - 1 = 6)

#### B∆∞·ªõc 5: Hu·∫•n Luy·ªán v√† ƒê√°nh Gi√° M√¥ H√¨nh (`modeling_final.ipynb`)

**M·ª•c ti√™u:** X√¢y d·ª±ng v√† so s√°nh c√°c m√¥ h√¨nh ph√¢n lo·∫°i

**Pipeline Modeling Ho√†n Ch·ªânh:**

```python
pipeline_modeling(
    df_train_valid,          # DataFrame train+validation
    df_test,                 # DataFrame test
    train_size,              # T·ª∑ l·ªá train (8, 7, ho·∫∑c 6)
    valid_size,              # T·ª∑ l·ªá valid (2, 3, ho·∫∑c 4)
    random_state=11,
    vectorizer="tf_idf", min_df=2, max_df=0.95, max_features=8000,
    discriminant="none",     # "none", "pca", ho·∫∑c "lda"
    model_type="logistic",   # "logistic_regression" ho·∫∑c "knn"
    n_components_pca=0.9,    # Gi·ªØ 90% variance cho PCA
    n_components_lda=6,      # 6 chi·ªÅu cho LDA
    max_iter=1000,           # S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa
    metric='cosine'          # metric trong knn
)
```

**C√°c b∆∞·ªõc trong pipeline:**

1. **Chia d·ªØ li·ªáu**
   - T√°ch train-validation-test theo t·ª∑ l·ªá ch·ªâ ƒë·ªãnh
   - S·ª≠ d·ª•ng stratified split ƒë·ªÉ ƒë·∫£m b·∫£o ph√¢n b·ªë nh√£n

2. **TF-IDF Vectorization**
   - `max_features=8000` - Ch·ªâ gi·ªØ 8000 t·ª´ ph·ªï bi·∫øn nh·∫•t
   - `ngram_range=(1, 2)` - S·ª≠ d·ª•ng unigram v√† bigram
   - `min_df=2` - T·ª´ ph·∫£i xu·∫•t hi·ªán √≠t nh·∫•t 2 l·∫ßn
   - `max_df=0.95` - Lo·∫°i b·ªè t·ª´ xu·∫•t hi·ªán qu√° 95% documents

3. **Gi·∫£m chi·ªÅu (t√πy ch·ªçn)**
   - √Åp d·ª•ng PCA ho·∫∑c LDA n·∫øu ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
   - Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu sang kh√¥ng gian m·ªõi

4. **Hu·∫•n luy·ªán m√¥ h√¨nh**
   - Logistic Regression v·ªõi class_weight='balanced'
   - K-NN v·ªõi n_neighbors=83 v√† metric='cosine'

5. **D·ª± ƒëo√°n v√† ƒë√°nh gi√°**
   - D·ª± ƒëo√°n tr√™n c·∫£ 3 t·∫≠p: train, validation, test
   - T√≠nh to√°n c√°c metrics

**M√¥ h√¨nh Machine Learning:**

1. **Logistic Regression (Multinomial Softmax)**
   ```python
   LogisticRegression(
       multi_class='multinomial',    # Softmax cho ƒëa l·ªõp
       class_weight='balanced',      # X·ª≠ l√Ω imbalanced data
       max_iter=1000                 # S·ªë l·∫ßn l·∫∑p
   )
   ```
   - B√†i to√°n ph√¢n lo·∫°i ƒëa l·ªõp

2. **K-Nearest Neighbors (K-NN)**
   ```python
   KNeighborsClassifier(
       n_neighbors=83,     # S·ªë l∆∞·ª£ng l√°ng gi·ªÅng (t·ªëi ∆∞u t·ª´ grid search)
       metric='cosine',    # S·ª≠ d·ª•ng cosine similarity
       n_jobs=-1          # S·ª≠ d·ª•ng t·∫•t c·∫£ CPU cores
   )
   ```
   - D·ª±a tr√™n nguy√™n l√Ω "l√°ng gi·ªÅng g·∫ßn nh·∫•t"
   - Cosine similarity

---

## VI. K·ªãch B·∫£n Th·ª±c Nghi·ªám

D·ª± √°n th·ª±c hi·ªán **18 k·ªãch b·∫£n th·ª±c nghi·ªám** kh√°c nhau, k·∫øt h·ª£p:
- **3 t·ª∑ l·ªá chia d·ªØ li·ªáu:** 8:2, 7:3, 6:4 (Train:Validation)
- **3 ph∆∞∆°ng ph√°p x·ª≠ l√Ω chi·ªÅu:** None, PCA, LDA
- **2 m√¥ h√¨nh:** Logistic Regression, K-NN

### Ma Tr·∫≠n Th·ª±c Nghi·ªám

| ID | Train:Valid | Gi·∫£m Chi·ªÅu | M√¥ H√¨nh | M√¥ T·∫£ |
|----|-------------|------------|---------|--------|
| 1  | 8:2 | None | Logistic | Baseline Logistic Regression v·ªõi 8:2 |
| 2  | 8:2 | PCA | Logistic | Gi·∫£m chi·ªÅu kh√¥ng gi√°m s√°t |
| 3  | 8:2 | LDA | Logistic | Gi·∫£m chi·ªÅu c√≥ gi√°m s√°t |
| 4  | 8:2 | None | K-NN | Baseline v·ªõi K-NN |
| 5  | 8:2 | PCA | K-NN | K-NN v·ªõi PCA |
| 6  | 8:2 | LDA | K-NN | K-NN v·ªõi LDA |
| 7  | 7:3 | None | Logistic | TƒÉng t·∫≠p validation (7:3) |
| 8  | 7:3 | PCA | Logistic | 7:3 v·ªõi PCA |
| 9  | 7:3 | LDA | Logistic | 7:3 v·ªõi LDA |
| 10 | 7:3 | None | K-NN | 7:3 baseline K-NN |
| 11 | 7:3 | PCA | K-NN | 7:3 K-NN v·ªõi PCA |
| 12 | 7:3 | LDA | K-NN | 7:3 K-NN v·ªõi LDA |
| 13 | 6:4 | None | Logistic | TƒÉng t·∫≠p validation (6:4) |
| 14 | 6:4 | PCA | Logistic | 6:4 v·ªõi PCA |
| 15 | 6:4 | LDA | Logistic | 6:4 v·ªõi LDA |
| 16 | 6:4 | None | K-NN | 6:4 baseline K-NN |
| 17 | 6:4 | PCA | K-NN | 6:4 K-NN v·ªõi PCA |
| 18 | 6:4 | LDA | K-NN | 6:4 K-NN v·ªõi LDA |

### V√≠ D·ª• Ch·∫°y Th·ª±c Nghi·ªám

**K·ªãch b·∫£n 2: Logistic Regression v·ªõi PCA, t·ª∑ l·ªá 8:2**

```python
model, train, valid, test, pred = pipeline_modeling(
    train_valid_processed_comments,
    test_processed_comments,
    train_size=8,
    valid_size=2,
    discriminant="pca",
    n_components_pca=0.9,
    model_type="logistic_regression",
    max_iter=1000
)

# ƒê√°nh gi√°
pipeline_evaluation(
    train[1], valid[1], test[1],
    pred[0], pred[1], pred[2],
    train_size=8, valid_size=2,
    discriminant="pca",
    model_type="logistic_regression",
    show_plot=True
)
```

### C√°c Metrics ƒê√°nh Gi√°

D·ª± √°n s·ª≠ d·ª•ng 4 metrics ch√≠nh:

1. **Accuracy (ƒê·ªô ch√≠nh x√°c)**
   - T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng tr√™n t·ªïng s·ªë m·∫´u
   - C√¥ng th·ª©c: (TP + TN) / (TP + TN + FP + FN)

2. **Precision (ƒê·ªô ch√≠nh x√°c d∆∞∆°ng)**
   - T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng trong c√°c m·∫´u ƒë∆∞·ª£c d·ª± ƒëo√°n l√† positive
   - C√¥ng th·ª©c: TP / (TP + FP)
   - S·ª≠ d·ª•ng weighted average cho ƒëa l·ªõp

3. **Recall (ƒê·ªô bao ph·ªß)**
   - T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng trong c√°c m·∫´u th·ª±c t·∫ø l√† positive
   - C√¥ng th·ª©c: TP / (TP + FN)
   - S·ª≠ d·ª•ng weighted average cho ƒëa l·ªõp

4. **F1-Score (ƒêi·ªÉm F1)**
   - Trung b√¨nh ƒëi·ªÅu h√≤a c·ªßa Precision v√† Recall
   - C√¥ng th·ª©c: 2 * (Precision * Recall) / (Precision + Recall)
   - C√¢n b·∫±ng gi·ªØa precision v√† recall

**Tr·ª±c quan h√≥a:**
- Confusion Matrix (Ma tr·∫≠n nh·∫ßm l·∫´n) ƒë∆∞·ª£c chu·∫©n h√≥a
- Hi·ªÉn th·ªã cho c·∫£ 3 t·∫≠p: Train, Validation, Test

---

## VII. H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng

### 1. Y√™u C·∫ßu H·ªá Th·ªëng

**M√¥i tr∆∞·ªùng:**
- Python 3.8 tr·ªü l√™n
- Jupyter Notebook ho·∫∑c JupyterLab
- RAM: T·ªëi thi·ªÉu 8GB (khuy·∫øn ngh·ªã 16GB)
- CPU: Multi-core (K-NN y√™u c·∫ßu nhi·ªÅu CPU)

**Th∆∞ vi·ªán c·∫ßn thi·∫øt:**

```bash
pip install pandas numpy matplotlib seaborn
pip install scikit-learn
pip install underthesea
pip install datasets
pip install wordcloud
pip install gensim
```

### 2. C√°ch Ch·∫°y D·ª± √Ån

#### Ch·∫°y To√†n B·ªô Pipeline (T·ª´ ƒê·∫ßu)

**B∆∞·ªõc 1: X√¢y d·ª±ng d·ªØ li·ªáu**
```bash
# M·ªü v√† ch·∫°y data_build.ipynb
jupyter notebook data_build.ipynb
```
- T·∫£i UIT-VSMEC t·ª´ Hugging Face
- G·ªôp v·ªõi d·ªØ li·ªáu t·ª± g√°n nh√£n
- Output: `data/raw_data_final.csv`

**B∆∞·ªõc 2: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu**
```bash
# M·ªü v√† ch·∫°y preprocessing_final_final.ipynb
jupyter notebook preprocessing.ipynb
```
- √Åp d·ª•ng 13 b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω
- Output: `data/cleaned_final/processed_comments.csv`

**B∆∞·ªõc 3: Ph√¢n t√≠ch d·ªØ li·ªáu (EDA)**
```bash
# M·ªü v√† ch·∫°y eda.ipynb
jupyter notebook eda.ipynb
```
- Ph√¢n t√≠ch th·ªëng k√™ v√† tr·ª±c quan h√≥a
- Lo·∫°i b·ªè outliers
- Chia t·∫≠p train-validation-test
- Output: `train_valid_processed_comments.csv` v√† `test_processed_comments.csv`

**B∆∞·ªõc 4: Hu·∫•n luy·ªán m√¥ h√¨nh**
```bash
# M·ªü v√† ch·∫°y modeling_final.ipynb
jupyter notebook modeling.ipynb
```
- Ch·∫°y 18 k·ªãch b·∫£n th·ª±c nghi·ªám
- ƒê√°nh gi√° v√† so s√°nh k·∫øt qu·∫£

#### Ch·∫°y Nhanh (Ch·ªâ Modeling)

N·∫øu d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω s·∫µn trong th∆∞ m·ª•c `data/cleaned_final/`:

```python
# M·ªü modeling_final.ipynb v√† ch·∫°y t·ª´ ƒë·∫ßu
# Ch·ªçn k·ªãch b·∫£n th·ª±c nghi·ªám mong mu·ªën

# V√≠ d·ª•: Ch·∫°y k·ªãch b·∫£n Logistic + PCA + 8:2
model, train, valid, test, pred = pipeline_modeling(
    train_valid_processed_comments,
    test_processed_comments,
    train_size=8,
    valid_size=2,
    discriminant="pca",
    model_type="logistic_regression",
    max_iter=1000
)
```

### T√πy Ch·ªânh Th·ª±c Nghi·ªám

**Thay ƒë·ªïi t·ª∑ l·ªá chia d·ªØ li·ªáu:**
```python
# 8:2 - Nhi·ªÅu d·ªØ li·ªáu training
train_size=8, valid_size=2

# 7:3 - C√¢n b·∫±ng
train_size=7, valid_size=3

# 6:4 - Nhi·ªÅu d·ªØ li·ªáu validation
train_size=6, valid_size=4
```

**Ch·ªçn ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu:**
```python
# Kh√¥ng gi·∫£m chi·ªÅu
discriminant="none"

# PCA gi·ªØ 90% variance
discriminant="pca", n_components_pca=0.9

# LDA gi·∫£m xu·ªëng 6 chi·ªÅu
discriminant="lda", n_components_lda=6
```

**Ch·ªçn m√¥ h√¨nh:**
```python
# Logistic Regression
model_type="logistic_regression"

# K-Nearest Neighbors
model_type="knn"
```

**T√πy ch·ªânh TF-IDF:**
```python
# Trong h√†m pipeline_modeling, c√≥ th·ªÉ thay ƒë·ªïi:
max_features=8000,  # S·ªë t·ª´ v·ª±ng t·ªëi ƒëa
min_df=2,           # T·ª´ xu·∫•t hi·ªán t·ªëi thi·ªÉu
max_df=0.95         # T·ª´ xu·∫•t hi·ªán t·ªëi ƒëa
```

---

## VIII. K·∫øt Qu·∫£ v√† Ph√¢n T√≠ch

### Bi·ªÉu ƒê·ªì Confusion Matrix

M·ªói th·ª±c nghi·ªám t·∫°o ra 3 confusion matrices:
1. **Train set** - ƒê√°nh gi√° overfitting
2. **Validation set** - ƒêi·ªÅu ch·ªânh hyperparameters
3. **Test set** - ƒê√°nh gi√° cu·ªëi c√πng

### H∆∞·ªõng C·∫£i Thi·ªán

**V·ªÅ d·ªØ li·ªáu:**
- Thu th·∫≠p th√™m d·ªØ li·ªáu cho c√°c nh√£n thi·ªÉu s·ªë
- C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng g√°n nh√£n

**V·ªÅ m√¥ h√¨nh:**
- Th·ª≠ nghi·ªám c√°c m√¥ h√¨nh deep learning (LSTM, Transformer)
- S·ª≠ d·ª•ng pre-trained models (PhoBERT, ViT5)

**V·ªÅ ƒë√°nh gi√°:**
- √Åp d·ª•ng k-fold cross-validation
- Grid search cho hyperparameters
- Ph√¢n t√≠ch chi ti·∫øt c√°c l·ªói ph√¢n lo·∫°i

---

## ƒ®. T√†i Li·ªáu Tham Kh·∫£o

**Dataset:**
- UIT-VSMEC: [https://huggingface.co/datasets/ura-hcmut/UIT-VSMEC](https://huggingface.co/datasets/ura-hcmut/UIT-VSMEC)

**Th∆∞ vi·ªán:**
- Underthesea: [https://github.com/undertheseanlp/underthesea](https://github.com/undertheseanlp/underthesea)
- Scikit-learn: [https://scikit-learn.org/](https://scikit-learn.org/)
- Hugging Face Datasets: [https://huggingface.co/docs/datasets](https://huggingface.co/docs/datasets)

**Ph∆∞∆°ng ph√°p:**
- TF-IDF: Term Frequency-Inverse Document Frequency
- PCA: Principal Component Analysis
- LDA: Linear Discriminant Analysis
- Logistic Regression: Multinomial Softmax
- K-NN: K-Nearest Neighbors with Cosine Similarity